{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Distributions in Hyperbolic space\n",
    "`Drew Wilimitis`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent publications have demonstrated how to produce a Gaussian like distribution on hyperbolic space, which is the foundation of probabilistic models. Gaussian Mixture models and Expectation-Maximization (EM) have several advantages over KMeans clustering, such as providing probabilistic or fuzzy classifications and not requiring KMeans assumptions like 'circularity'.   <br>\n",
    "<br>\n",
    "I'll first explore the formulation of the pseudo-Gaussian, Wrapped Normal Distribution in the hyperboloid model **[1]**, and then I'll explore another proposal that gives an explicit form of a Gaussian distribution in the Poincaré disk **[2]**. <br>\n",
    "\n",
    "Finally, I will then attempt to use the hyperbolic gaussian distribution with the Expectation-maximization algorithm to implement a gaussian mixture model in hyperbolic space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard EM Algorithm with Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**: Training data  $x_1, \\ldots , x_n\\in \\mathbb{R}^{d}$ and specified number of source components/gaussian clusters $k$:<br>\n",
    "\n",
    "**Goal**: Perform clustering on input data and return cluster assignments <br>\n",
    "1. **Initialization step**: Initialize gaussian mean, covariance $(\\mu_k , \\Sigma_k)$ for each gaussian cluster $\\mathcal{G}(\\boldsymbol{\\mu_k}, \\Sigma_k)$ and initialize cluster assignments<br>\n",
    "2. **E-step**: For each data point $x_i$, and for each cluster label $k$, compute probability $p\\left(y_{i}=k | x_{i}, \\Theta^{(t)}\\right)$ of class assignment <br>\n",
    "3. **M-step**: Update parameters $\\Theta^{(t+1)}$ by computing new means and covariances based on updated class assignment probabilities <br>\n",
    "4. **Repeat steps 2-3 until stopping criteria** <br>\n",
    "5. **Return:** cluster labels for all $x_i$ and final parametrized gaussian cluster $\\mathcal{G_k}(\\boldsymbol{\\mu_k}, \\Sigma_k)$ for all $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T09:30:26.442582Z",
     "start_time": "2020-01-02T09:30:23.611032Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# import modules within repository\n",
    "sys.path.append('C:\\\\Users\\\\dreww\\\\Desktop\\\\hyperbolic-learning\\\\utils') # path to utils folder\n",
    "from utils import *\n",
    "from embed import train_embeddings, load_embeddings, evaluate_model\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore');\n",
    "\n",
    "# display multiple outputs within a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Wrapped Normal Distribution in the Lorentz Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapped normal distribution presented in **[1]** has the advantage of offering a fully differentiable probability density function, which is highly advantageous for gradient descent algorithms. This contruction might involve complications, however, with its projections and transformations between spaces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lorentz Model Background & Definitions** <br>\n",
    "\n",
    "Lorentz model has simpler closed form geodesics and particularly cleaner expressions for the exponential map and parallel transport. <br>\n",
    "\n",
    "We have the lorentzian product:\n",
    "$$\n",
    "\\left\\langle\\boldsymbol{z}, \\boldsymbol{z}^{\\prime}\\right\\rangle_{\\mathcal{L}}=-z_{0} z_{0}^{\\prime}+\\sum_{i=1}^{n} z_{i} z_{i}^{\\prime}\n",
    "$$ <br>\n",
    "which we use to define the hyperboloid/Lorentz model as the following set:\n",
    "\n",
    "$$\n",
    "\\mathbb{H}^{n}=\\left\\{\\boldsymbol{z} \\in \\mathbb{R}^{n+1}:\\langle\\boldsymbol{z}, \\boldsymbol{z}\\rangle_{\\mathcal{L}}=-1, \\quad z_{0}>0\\right\\}\n",
    "$$ <br>\n",
    "\n",
    "The lorentzian distance is given by: $$\n",
    "d_{\\ell}\\left(\\boldsymbol{z}, \\boldsymbol{z}^{\\prime}\\right)=\\operatorname{arccosh}\\left(-\\left\\langle\\boldsymbol{z}, \\boldsymbol{z}^{\\prime}\\right\\rangle_{\\mathcal{L}}\\right)\n",
    "$$ <br>\n",
    "\n",
    "and finally we set this vector as the origin: \n",
    "$$\n",
    "\\boldsymbol{\\mu}_{0}=[1,0,0, \\ldots .0] \\in \\mathbb{H}^{n} \\subset \\mathbb{R}^{n+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parallel transport** <br>\n",
    "\n",
    "Parallel transport takes some $v$ to $u$ by mapping between tangent spaces $T_{\\nu} \\mathbb{H}^{n}$ to $T_{\\mu} \\mathbb{H}^{n}$ along the geodesic in a parallel manner<br>\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\mathrm{PT}_{\\nu \\rightarrow \\mu}(\\boldsymbol{v})=\\boldsymbol{v}+\\frac{\\langle\\boldsymbol{\\mu}-\\alpha \\boldsymbol{\\nu}, \\boldsymbol{v}\\rangle_{\\mathcal{L}}}{\\alpha+1}(\\boldsymbol{\\nu}+\\boldsymbol{\\mu})\n",
    "$$ where $\\alpha=-\\langle\\boldsymbol{v}, \\boldsymbol{\\mu}\\rangle_{\\mathcal{L}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-01T20:46:54.616793Z",
     "start_time": "2020-01-01T20:46:54.608812Z"
    }
   },
   "source": [
    "**Exponential Map** <br>\n",
    "\n",
    "The exponential map: $\\exp _{\\mu}: T_{\\mu} \\mathbb{H}^{n} \\rightarrow \\mathbb{H}^{n}$  projects some vector $u$ from a tangent space of the hyperboloid to a vector $z \\in \\mathbb{H}^{n}$\n",
    "<br>\n",
    "\n",
    "$$\n",
    "z=\\exp _{\\mu}(\\boldsymbol{u})=\\cosh \\left(\\|\\boldsymbol{u}\\|_{L}\\right) \\boldsymbol{\\mu}+\\sinh \\left(\\|\\boldsymbol{u}\\|_{L}\\right) \\frac{\\boldsymbol{u}}{\\|\\boldsymbol{u}\\|_{\\mathcal{L}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Algorithm Outline:** Defining hyperbolic gaussian distribution $\\mathcal{G}(\\boldsymbol{\\mu}, \\Sigma)$ with $\\mu \\in \\mathbb{H}^{n}$ and positive definite $\\Sigma .$\n",
    "___ \n",
    "\n",
    "1. Sample a vector ${\\boldsymbol{v}^{*}}$ from the Gaussian distribution $\\mathcal{N}(\\mathbf{0}, \\mathbf{\\Sigma}) \\text { defined over } \\mathbb{R}^{n}$\n",
    "2. Interpret ${\\boldsymbol{v}^{*}}$ as an element of $T_{\\boldsymbol{\\mu}_{0}} \\mathbb{H}^{n} \\subset \\mathbb{R}^{n+1}$ by rewriting\n",
    "$ {\\boldsymbol{v}^{*}} \\text { as } \\boldsymbol{v}=[0, {\\boldsymbol{v}^{*}}]$<br>\n",
    "\n",
    "3. Parallel transport the vector $\\boldsymbol{v} \\ $  to  $\\ \\boldsymbol{u} \\in T_{\\boldsymbol{\\mu}} \\mathbb{H}^{n} \\subset \\mathbb{R}^{n+1}$\n",
    "along the geodesic from $\\mu_{0}$ to $\\mu$ <br>\n",
    "\n",
    "4. Map $u$ to $\\mathbb{H}^{n}$ by $\\exp _{\\mu}$\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:01:19.947452Z",
     "start_time": "2020-01-02T10:01:19.938464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -1.12827135, -0.25262686])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first get sample from standard multivariate gaussian \n",
    "def init_sample(dim = 2):\n",
    "    mean = np.zeros((dim))\n",
    "    cov = np.eye(dim)\n",
    "    v = np.random.multivariate_normal(mean, cov)\n",
    "    tangent_0 = np.insert(v, 0, 0)\n",
    "    return tangent_0\n",
    "init_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T10:14:50.099256Z",
     "start_time": "2020-01-02T10:14:50.090271Z"
    }
   },
   "outputs": [],
   "source": [
    "# define alternate minkowski/hyperboloid bilinear form\n",
    "def lorentz_product(u, v):\n",
    "    return -u[0]*v[0] + np.dot(u[1:], v[1:])\n",
    "\n",
    "def lorentz_norm(u):\n",
    "    return np.sqrt(lorentz_product(u,u))\n",
    "\n",
    "def parallel_transport(v, u):\n",
    "    \"\"\"Mapping between tangent spaces, transports vector along geodesic from v to u\"\"\" \n",
    "    alpha = -lorentz_product(v, u)\n",
    "    frac = lorentz_product(u - alpha*v, v) / (alpha+1)\n",
    "    return v + frac*(v + u)\n",
    "\n",
    "def exp_map(v, u):\n",
    "    \"\"\"Given v in tangent space of u, we project v onto the hyperboloid surface\"\"\" \n",
    "    first = np.cosh(lorentz_norm(v)) * u \n",
    "    last = np.sinh(lorentz_norm(v)) * (v / lorentz_norm(v))\n",
    "    return first + last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Explicitly defined Gaussian in the Poincare Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A closed form expression for the gaussian density is highly advantageous, however, this density is not fully differentiable and might be significantly harder to sample from this gaussian density in hyperbolic space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(\\mathbf{x} | \\boldsymbol{\\mu}, \\boldsymbol{\\sigma})=\\frac{1}{Z(\\boldsymbol{\\sigma})} e^{-\\frac{d^{2}(\\boldsymbol{x}, \\boldsymbol{\\mu})}{2 \\sigma^{2}}} \\quad Z(\\boldsymbol{\\sigma})=2 \\pi \\sqrt{\\frac{\\pi}{2}} \\boldsymbol{\\sigma} e^{\\frac{\\sigma^{2}}{2}} \\operatorname{erf}\\left(\\frac{\\boldsymbol{\\sigma}}{\\sqrt{2}}\\right)\n",
    "$$ <br>\n",
    "Error function term given by: $$\n",
    "\\begin{aligned}\n",
    "\\operatorname{erf}(x) &=\\frac{1}{\\sqrt{\\pi}} \\int_{-x}^{x} e^{-t^{2}} d t \\\\\n",
    "&=\\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^{2}} d t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The density is somewhat similar to the Euclidean case, but here the distance becomes the Poincaré distance, and the parameters are the Frechet mean $\\boldsymbol{\\mu}$, and the dispersion $\\sigma > 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sample_hyperboloid_disc(max_distance, centre=None):\n",
    "    \"\"\"\n",
    "    Return a sample drawn uniformly at random from the disc of\n",
    "    radius `max_distance` on the hyperboloid.\n",
    "    NOTE: formula is specific to the case of local-dimension 2.\n",
    "    \"\"\"\n",
    "    rank = 2\n",
    "    tangent = np.random.randn(rank + 1)\n",
    "    tangent[rank] = 0\n",
    "    tangent /= np.sqrt(tangent.dot(tangent))\n",
    "    # we use inversion sampling: invert the CDF, apply result to uniform random samples from [0,1]\n",
    "    p = np.random.uniform()\n",
    "    tangent *= np.arccosh(1 + p * (np.cosh(max_distance) - 1))\n",
    "    basept = coordinate_vector(rank, rank + 1)\n",
    "    if centre is None:\n",
    "        centre = basept\n",
    "    else:\n",
    "        centre_log = logarithm(basept, centre)\n",
    "        tangent = geodesic_parallel_transport(basept, centre_log, tangent)\n",
    "    return exponential(centre, tangent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "___\n",
    "\n",
    "**[1]** Nagano, Y., Yamaguchi, S., Fujita, Y., & Koyama, M. (2019). A Differentiable Gaussian-like Distribution on Hyperbolic Space for Gradient-Based Learning. ArXiv, abs/1902.02992. <br>\n",
    "\n",
    "**[2]** Ovinnikov, Ivan. “Poincaré Wasserstein Autoencoder.” ArXiv abs/1901.01427 (2019): n. pag."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
